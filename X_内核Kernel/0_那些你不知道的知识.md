### CPU三级缓存（Cache）

- CPU缓存是什么？
  - 为了解决CPU运行处理速度 >> 内存读写速度的矛盾
  - 我们来简单地打个比方：如果CPU在L1一级缓存中找到所需要的资料要用的时间为3个周期左右，那么在L2二级缓存找到资料的时间就要10个周期左右，L3三级缓存所需时间为50个周期左右；如果要到内存上去找呢，那就慢多了，可能需要几百个周期的时间。

- Cache存在的意义
  - 作为CPU与内存之间高速数据缓冲区
  - L1最靠近CPU核心，运行速度最快
- 原理
  - 局部性原理（最近访问的数据，将大概率被再次访问）

### 两个线程在单核CPU中能同时执行么？

- 不能
  - 我们平时所看到的多线程在单核CPU中并发执行（本质上不是并行执行），看起来是同时执行的，是由于CPU的调度，使得两个线程进行上下文切换，本质上在某个时间刻，只有一个线程在执行

### 既然CPU用一个时间只能执行一个线程，那么why存在并发问题

- 并发问题是由于CPU线程上下文切换导致的
  - CPU切换线程并不会管你的线程是否将代码执行完，而是和分给线程的时间片到期有关
  - 在时间片到期后，会保存线程的上下文，切换到另外一个线程执行
  - 线程A先执行i++，然后由于CPU调度发生线程切换，切换到线程B，线程B在执行i++，此后，切回线程A，但是线程A的i值仍然是当时保存的上下文的值，因此，就出现并发问题

```c++
void thread_func(){
    i++;
}
```

---

### 中断/信号

- 相同点
  - 异步通信方式
  - 暂停当前的，执行对应的handler程序
  - 处理完，都会返回原来的位置
  - 二者都是可以屏蔽的
- 不同点
  - 信号：用户态，中断：内核态
  - 中断有优先级，信号没有
  - 中断响应是及时的，信号响应一般有延迟



---

### 进程状态：可中断/不可中断

- ASK_INTERRUPTIBLE (可中断）

- ASK_UNINTERRUPTIBLE (不可中断）
  - 除了就算是接收到信号也不会被唤醒或准备投入运行外，这个状态与可打断状态相同
  - 这个状态通常在进程必须在等待时不受干扰或等待事件很快就会发生时出现。
  - 由于处于此状态的任务对信号不做响应，所以成为之不可中断状态，使用得较少
  - 这就是你在执ps命令时，看到那些被标为D状态而又不能被杀死的进程的原因。
    - 由于任务将不响应信号，因此，你不可能给它发送SIGKILL信号。
    - 退一步说，即使有办法，终结这样一个任务也不是明智的选择 ，因为该任务有可能正在执行重要的操作，甚至还可能持有一个佶号置

---

### RST分节、缓冲区

- A调用close关闭全双工连接过程
  - 要等待缓冲区的数据全部收发完毕，才断开
- RST分节
  - SO_LINGER标记
  - A向B发送了RST分节后，如果缓冲区中有数据，那么缓冲区中的数据将会被直接丢弃，然后A端断开连接
    - 此时B收到RST分节后，将会直接断开连接

---

### 共享内存 / nattch、status、PRIVATE

- ipcs -m 查看共享内存的状态
  - nattch:
    - 当前连接该shm的进程数
  - status
    - 其中显示“dest”表示共享内存段已经被删除，但是还有用户在使用它
    - 当用户调用shmctl的IPC_RMID时，内存先查看多少个进程与这个内存关联着，如果nattch关联数为0，就会销毁这段共享内存，否则设置这段内存的mod的mode位为SHM_DEST
  - PRIVATE
    - shm调用ftok会生成一个shmid标识该shm
    - 使用IPC_PRIVATE创建的IPC对象, key值属性为0，和IPC对象的编号就没有了对应关系
    - 这样毫无关系的进程，就不能通过key值来得到IPC对象的编号（因为这种方式创建的IPC对象的key值都是0）。
    - 因此，这种方式产生的IPC对象，和无名管道类似，不能用于毫无关系的进程间通信。
    - 但也不是一点用处都没有，仍然可以用于有亲缘关系的进程间通信。

---

### [Linux并发控制—顺序锁（seqlock）](https://blog.csdn.net/weixin_38233274/article/details/79276359)

- 顺序锁，是对读写锁的优化，提高了并发（适用与“读多写少”的场景）
  - 读写锁
    - 同一个时刻，只要有写，就不允许读
  - 顺序锁
    - 允许同一个时刻，有读写共存（写锁不会阻塞读锁，读锁不会阻塞写锁）
- seq锁的限制
  - 不允许枷锁区域内有指针
    - 因为，允许同一个时刻有读有些，所以，写操作可能会使指针失效，导致读操作访问指针时，访问了非法内存，系统崩溃
- seq锁实现原理（递增整数seq）
  - 写锁进入临界区，seq++；写锁退出临界区seq--
    - ==> seq为奇数，表示有写操作进入临界区，写进行
    - ==> seq为偶数，表示写操作离开临界区，写完成
  - 当临界区加了写锁
    - 之后，又有读锁到来时，会发现seq为奇数，那么，读操作等待seq变为偶数
  - 当临界区加了读锁，记录seq值
    - 之后，写操作到来，写操作可以操作临界区，此时seq++
    - 当读锁退出临界区之前，会比较seq是否变化，如果变化，则说明读到的数据被写操作更改，此时，重新读取数据，直到seq值不变位置

---

### CAS、ABA

CAS是乐观锁的实现（无所算法），Compare and Swap，比较再交换



- CAS(V，A，B) : 内存值V、旧的预期值A，新值B
  - 当A==V时，将V改为B，否则什么都不做
- 优点
  - CAS是CPU指令级开销，只有一步原子操作，所以非常快
- 缺点
  - 循环时间长开销很大
    - 配合无线循环一起使用，如果CAS执行失败，会一直尝试，如果长时间不成功，会带来CPU性能开销
  - ABA问题

---

- ABA问题
  - V==A
  - 如果此时，V被修改之后，再改回A
  - 此时，V==A：CAS依然能执行成功，此时的状态并不是最初的状态了，可能发生意想不到的错误
- ABA问题解决（添加版本号）
  - 除了比较V==A，还添加一个版本号，如果临界区的内容被更新，版本号++
  - 当退出临界区时，判断版本号是否一致
    - 一致，执行成功
    - 不一致，失败，再次执行

---

### TCP滑动窗口和socket缓冲区之间的关系

- TCP的滑动窗口大小实际上就是socket的接收缓冲区大小的字节数



---

### .so的调用

```c++
// dlopen：载入so动态库
dll_handle = dlopen("test.so");
// dlsym：加载函数"create"的函数地址，保存在函数指针中create_func
create_fun = (so_init) dlsym(dll_handle, "create");
// 使用函数指针，调用该函数
create_fun();
```

---

### [可变参数的原理/实现方式](https://blog.csdn.net/qq_32693119/article/details/88569428)

- 可变参数的参数，是从右向左入栈的（最左面的参数，在栈顶：因此，我们就知道了最左参数 fmt 的地址）

  ```c++
  // 我们知道了最左参数fmt的地址，可以求出后面的参数地址
  // 仅凭函数声明，我们无法知道参数的个数，类型
  void var_args_func(const char * fmt, ...) 
  {
      ... ... 
  }
  fixed_args_func(17, 5.40, "hello world");
  fixed_args_func(a, b, c);
  我们知道a的地址，那么b，c的地址，就可以求出：
      b.addr = a.addr + sizeof(a)  // 其实，此处并不能简单的使用sizeof
      c.addr = b.addr + sizeof(b)  //      因为，要进行内存对齐，才能找到真正的地址
  ```


### c10K问题

- c10K问题的由来
  - 随着互联网的普及，应用的用户群体几何倍增长，此时服务器性能问题就出现。
  - 最初的服务器是基于进程/线程模型。新到来一个TCP连接，就需要分配一个进程。
  - 假如有C10K，就需要创建1W个进程，可想而知单机是无法承受的。
  - 那么如何突破单机性能是高性能网络编程必须要面对的问题，进而这些局限和问题就统称为C10K问题
- c10K问题的本质
  - 创建过多的线程，OS频繁切换线程，抢占资源，难以承受开销
- C10K问题的解决方案
  - IO多路复用：一个进程，处理百万级别的请求

---



### [sleep和wait区别](https://blog.csdn.net/qq_20009015/article/details/89980966)

其实就是讲它们在使用场景

> wait就是条件变量
>
> sleep是系统调用，它会使当前线程进入可中段睡眠状态，会被信号唤醒

对比

> - 相同点
>
>   > sleep,wait调用后都会暂停当前线程并让出cpu的执行时间
>   >
>   > 它们都可以被interrupted方法中断
>
> - 不同点 （是否会解锁）
>
>   > sleep不会释放当前持有的对象的锁资源，到时间后（超时后），sleep会被唤醒，进而继续执行
>   >
>   > 而wait会放弃所有锁并需要notify/notifyAll后重新获取到对象锁资源后才能继续执行



### 端口扫描（黑客）



---

### exec(“ls”)

- 使用

  > fork创建一个子进程
  >
  > 子进程中调用exec，执行其他的可执行程序（如，ls）
  >
  > exec的功能是，实现代码替换，它并没有创建新的子进程

- 在shell执行ls命令，实际上就是先创建了子进程，然后执行exec加载了ls程序

- 在用fork创建子进程后，子进程往往要调用exec函数，以执行另一个程序

- 当在子进程调用一种exec函数时，该进程完全由新程序替换，它会加载新的代码段/正文/数据段/堆/栈，替换父进程的代码段…
- exec并不创建新进程，所以前后的进程ID并未改变

----

### fork与线程

- 在linux中，fork的时候，只复制了当前线程到子进程，也就是说，除了调用fork的线程外，其他线程在fork后的子进程中“蒸发”了。

- 危险

  基础知识：fork，子进程会继承父进程的锁

  > 假设在fork之前，一个线程对某个锁进行了lock操作，然后另外一个线程调用了fork创建了子进程。可以在子进程中持有那个锁的线程却“消失了”，从子进程的角度上看，这个锁，被“永久”的上锁了，因为它的持有者“蒸发”了。

- 解决方案

  如果，真的需要在线程中调用fork，那么可以尝试使用pthread_atfork

  ```c++
  int pthread_atfork(void (*prepare)(void), void (*parent)void(), void (*child)(void));
  ```

  > - prepare：在fork创建子进程之前调用
  >   - 该函数的任务是获取父进程定义的所有锁
  > - parent：在fork创建了子进程后，但在fork返回之前在父进程环境中调用
  >   - 该函数的任务是对prepare获取的所有锁解锁
  > - child：在fork返回之前，在子进程环境中调用
  >   - 与parent处理函数一样，该函数的任务也是对prepare获取的所有锁解锁
  >
  > 因为子进程继承了父进程的锁的拷贝，所以上述并不是解锁了两次，而是各自独占解锁
  >
  > - 需要注意的是pthread_atfork只能清理锁，但不能清理条件变量。

----

### linux 惊群

- 进程惊群
  1. Linux解决了多进程accept（内核解决了accept惊群）：选取<u>第一个进程</u>，让其accept返回；其他进程，accept不返回
  2. Linux没解决多进程epoll_wait（epoll_wait会产生惊群现象）：因为epoll监听的是文件描述符，除了可能后续被accept调用外，还有可能是其他网络IO事件的，而其他IO事件是否只能由一个进程处理，是不一定的，内核不能保证这一点
- 多线程惊群：条件变量
  1. pthread_cond_signal：唤醒所有wait条件变量的线程，只有一个可以被唤醒。

