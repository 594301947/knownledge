# 前言

写在最前，本文主要以知识框架为主，根据自己对知识掌握的情况，进行知识点的梳理（有的知识点实际上上篇幅很大，但是由于自己已经理解，就没有详细叙述）。

- 为什么redis不能代替SQL进行数据存储

  MYSQL是关系型数据库，大部分数据是存储在磁盘上的，以二维表格存储；Redis是非关系型数据库，存放在内存中，以KV存储，一般，当并发量大时，且读很多时，采用Redis降低读压力，Redis一般存放热点数据

# Redis缓存

#  1. 底层数据结构

## 1.1. 简单动态字符串SDS

```C++
struct sds{
	int len;     // buf数组已经使用字符串的长度
	int free;    // buf数组未使用的长度
	char buf[];  // 保存字符串
};
```

### 1.1.1. 为什么要使用SDS，而不使用C字符串

- 背景
  - Redis作为缓存数据库，数据经常会被修改，造成内存重分配，影响性能。
- 原因详述
  1. SDS有len成员变量，可以在O(1)的时间复杂度获取长度信息
     - 即使反复执行strlen命令，也不会对系统性能造成任何影响
  2. 更安全：杜绝缓冲区溢出
     - 当SDS执行strcat/strcpy等函数时，会先检查free是否够用，不够用时，就扩增
  3. 减少重分配次数
     - 扩增：SDS会多分配free的空间，当需要扩容时，若free空间足够，直接改变len/free的值就可以
     - 缩短：缩短时，直接修改free的值，不需要释放旧空间，申请小的新空间存放新字符串

## 1.2. 哈希表

### 1.2.1. 数据结构

```c
// 哈希表
typedef struct dictEntry {
	void* key;  // 键
	union {     // 值
		void* val;
		uint64_t u64;
		int64_t  s64;
	} v;
	struct dictEntry* next; // 指向下一个哈希节点，形成链表
}dictEntry_t;

struct dictht {
	dictEntry_t **table;  // 数组，每个元素都是dictEntry_t*，它是一个链表头，所有冲突的key挂在相同链表上
	unsigned long size;   // 哈希表容量大小
	unsigned long used;   // 当前已经使用大小
}
```

```c
// 字典
struct dict {
	dictht ht[2];   // 2个哈希表: ht[0]正常情况下使用, ht[1]在rehash时使用
    int rehashidx;  // rehash索引 (没进行rehash时，该值为-1)
}
```

### 1.2.2. rehash（重新散列）

- 背景

  - 哈希表中键值对的增加/减少，都可能导致rehash（为了使哈希表的 `负载因子` 维持在合理的范围内）

- rehash过程（渐进式rehash）

  - ht[1]分配空间，新建一个空的哈希表
  - rehash索引计数器，由-1变为0，表示rehash正式开始
  - 将ht[0]中的元素，rehash重新散列到ht[1]上
    - 每次一个(key,value)键值对rehash成功后，rehash索引计数器都+1
  - 当所有的ht[0]都rehash到ht[1]中后，ht[0]被清空，此时将ht[0],ht[1]交换，rehash结束，最后将rehash索引设为-1

  :slightly_smiling_face:在rehash过程中，新增加的(key,value)键值对，怎么处理？

  - 答：会直接rehash到ht[1]上，这样做，会保证ht[0]只减不增

## 1.3. 压缩列表ziplist

- 使用场景

  - 列表键、哈希键: 含有少数的键，且键是“短整型”、“短字符串”

- 优点

  - 节省内存，实现简单，是连续内存块的顺序存储（有点像变长数组，它通过长度划分每个节点）

- 每个 `压缩列表节点` 构成

  - 前一个节点的长度pre_len 当前节点的长度、类型 
  - 当前节点的数据内容

- 连锁更新

  - 当插入和删除元素时，可能会导致连锁更新。

     ① （全small）原ziplist节点都是长度小于256：当在idx插入大于256的节点时，idx+1后面的节点e1的成员pre_len无法保存前一个节点的长度，因此，要重分配内存。这样e1内存就扩增了，因为是顺序存储，所以e2、e3后面的元素都要向后移动（更新） 

    ② （big1、small、big2）：当删除small时，将会引起big2后面的节点连锁更新

## 1.3. 跳跃表

- 结构

  - 是一个多层次的链表，每层节点的next跨度大小都不同，从上到下依次减小

- 时间复杂度

  - 性能可以和AVL树媲美，且实现简单

  - 最好O（lgN）
  - 最差O（N） 

- 使用场景

  - zset有序集合键

#  2. Redis五种数据结构

- 字符串键string |
  - 字符串类型的value最大能容纳512M 
- 列表键         
  - ziplist
  - linklist               
- 哈希键         
  - ziplist
  - hash-table            
- 集合           
  - intset
  - hash-table
- 有序集合键     
  - ziplist
  - 跳跃表                 
- 位图键 
  - bitmap                          

#  3. 删除机制

- 惰性删除： 只有访问时，采取查看该元素是否过期，过期才真正的删除。 
  - 优点：不需要频繁的删除，消耗CPU资源少 
  - 缺点：占用内存

- 定时删除：开启定时器，定时器到时间时，删除过期数据 
  - 优点：不占用内存
  - 缺点：消耗CPU资源少多

# 4. 持久化RDB/AOF

- 背景
  - Redis是内存数据库，数据保存在内存中，但是内存数据容易丢失，对此，Redis提供了持久化机制：RDB（Redis DataBase）\AOF（Append only file）

## 4.1. RDB

在指定时间间隔内，将内存中的数据和操作，通过【快照】的方式保存到RDB文件

- RDB三种触发机制

  - SAVE： save会阻塞Redis服务器进程，Redis不能处理客户端的其他命令请求，直到RDB文件创建完毕为止
  - 手动触发：bgsave会创建一个子进程，更新RDB文件，父进程可以继续处理请求 
  - 自动触发：通过Redis配置文件来完成
    - save m n：在m秒内数据集存在n次修改时，自动触发bgsave。
- 优点
  - RDB文件紧凑、全量备份，非常适合于备份和灾难恢复
  - RDB恢复速度比AOF快（AOF要进行重放）
- 缺点
  - 不安全，会丢失时间间隔内的数据
  - 全量备份，耗用时间多
  -  每次保存RDB文件时，都需要fork一个子进程来持久化，性能开销较大

## 4.2. AOF

Redis将每次更新写操作命令，都以追加方式写入AOF文件。重启时，只需要从头到尾执行一次AOF中的指令，可以恢复数据

**AOF的持久化的实现，可以分为 命令追加（append）、文件写入、文件同步（sync）**

- 命令追加
  - 在执行完一次更新命令后，会将该更新命令写入到aof_buf缓冲区
- 写入/同步：aof_buf缓冲区的数据，何时刷写入AOF文件（有下面三种触发机制）
  - always：每次更新，都写一次AOF（会丢失一次的数据）
  - everysec：每秒，写一次AOF （在1s内宕机，可能会数据丢失）
  - no：永不同步更新AOF（写入AOF时机，由OS控制）

---

- rewrite

  为了防止AOF文件过大，采用了rewrite机制。（将对同一个key的操作，合并成一个语句，写入AOF文件）

  - AOF 的 rewrite，是放在 `子进程` 里执行的
    - 在重写期间，服务器主进程依然能处理命令请求

:slightly_smiling_face: 子进程rewrite，存在一个问题：因为子进程在rewrite期间，主进程可能会收到客户端的更新，导致主进程数据和重写后的AOF文件数据不一致。

- 为了解决这个问题，AOF设置了重写缓冲区（在主进程创建子进程后，该重写缓冲区开始被使用）

  - 在子进程重写期间，主进程（服务器）要执行下面3个工作

    - 接收并执行客户端发来的命令请求
    - 将执行后的写命令，追加写入AOF缓冲区
    - 将执行后的写命令，追加写入AOF重写缓冲区

  - 这样做，可以保证：

    当子进程执行完重写后，会向主进程发送信号，此时，父进程调用该信号的处理函数，执行下面的工作

    - 将AOF重写缓冲区中的数据，写入新的AOF文件

  备注：在整个AOF后台重写过程中，只有信号处理函数执行时，才会使主进程造成阻塞

---

- 优点
  - AOF可以更好的保护数据不丢失
    - 一般AOF更新时间设置为1s，通过一个后台线程执行一次fsync，最多丢失1s的数据
- 缺点

  - 相同数据集，AOF文件要远大于RDB文件，恢复速度要重放（慢于RDB）

  - 一直更新写操作，会使AOF文件激增，极端场景下，会对硬盘空间造成压力 

---

写在最后，因为AOF的更新的频率更高，所以，当RDB与AOF同时开启后，优先使用AOF文件

---



# 5. 高可用

- 高可用
  - 当一台服务器宕机停止服务后，对业务及用户毫无影响

## 5.1. 主从复制

- 优点
  - 正常情况下，主机提供服务，并将数据同步到备份机器，当主机宕机后，备机立即开始服务 。
  - master宕机后，通过选举投票方式选择出新的master，继续提供服务。
  - 实现读写分离，提高并发性

**Redis的复制功能，分为 同步 和 命令传播**

### 5.1.1. 同步

- **主从复制的过程**

  - 从服务器向主服务器发送SYNC命令

  - 主服务器收到SYNC命令后

    - 执行BGSAVE，在后台生成RDB文件
    - 使用一个缓冲区记录从现在开始执行所有的新的更新命令

  - 主服务器

    - 执行BGSAVE后，会将RDB文件发送给从服务器
    - 将缓冲区中的新更新命令，发送给从服务器

  - 从服务器

    - 收到RDB后，加载RDB文件同步数据

    - 执行收到的缓冲区更新命令，此时，数据与主服务器一致

- **旧版本复制功能的缺陷（断线后，重新复制）**

  - 网络断线后，会重新全量复制

- **新版本解决了断线重复制问题**

  核心: 复制积压缓冲区、主服务器和从服务器都维护了自己的复制偏移量

  - 当主服务器向从服务器器传播N个字节的数据后，会把自己的复制偏移量+N
  - 从服务器收到主服务器传来的N个字节且更新成功后，也会将自己的复制偏移量+N

  因此，通过主从服务器的复制偏移量，就能知道此时二者是否处于一致性状态！

  - 主服务器，还维护了一个定长的复制积压缓冲区，每次向从服务器发送更新数据时，同时会向复制积压缓冲区写入数据
    - 当连接断开后，从服务器判断自己的复制偏移量offset是否在复制积压缓冲区中
      - 如果在，执行部分复制
      - 如果不在，执行全量复制

##  5.2. 哨兵

- 原理：哨兵将会监控集群中所有的节点；一般为了防止单哨兵节点故障，将配置多个哨兵协同合作。

- 切换过程

  - 主观下线：哨兵A检测到主节点下线后，将不会立即切换主节点，而是认为它客观下线 

  - 询问：哨兵A会询问监听该主节点的其他哨兵，收集汇总信息，当有足够多的主观下限信息时，判断是否为客观下线 

  - 选取新领头哨兵：当有一个哨兵判断为客观下限后，将会选举出领头哨兵，由它进行切换主节点操作

- 缺点

  - 运维复杂
  - 哨兵选主期间，不能对外提供服务（因此如果Master宕机后，不支持并发）

##  5.3. 集群

一个集群通常有多个服务器节点组成。 最开始时，各个服务器节点是相互独立的；之后，将各个节点连接起来

### 5.3.1. 槽指派

- 整个数据库，被划分为16384个槽，数据库的每个键都属于这个槽16384槽中的一个（每个槽记录了一个元组，即键值对），集群中的每个节点可以处理0个或16384个槽
- 当数据库的16384个槽都被分配/指派给节点处理后，集群才会进入上线状态，此时才可以接收和处理客户端发来的数据请求（如果任意一个槽没有分配给节点，就不会提供服务）

将槽分配到集群中某个节点的算法，一般采用取模算法、[一致性哈希算法](https://blog.csdn.net/weixin_36750623/article/details/84993780)。

### 5.3.2. 在集群中执行命令

- 当客户端向节点发送与数据库键有关的命令时，接收命令的节点会计算出命令要处理的数据库键属于哪个槽。
- 如果键所在的槽正好就指派给当前节点，那么当前节点直接执行该命令
- 如果键所在的槽没有指派给当前节点，那么节点会向客户端返回一个MOVED错误，指引客户端转向（redirect）至正确的节点，并再次发送之前想要执行的命令

### 5.3.3. 重新分片

定义：将任意数量已经指派给某个节点的槽，改为指派给另一个节点，并且相关槽所属的键值对也会从源节点移动到目标节点。

- 重新分片可以在线进行，即：在重新分片过程中，集群不需要下线，并且源节点和目标节点都可以继续处理命令请求

### 5.3.4. 复制

上面已经知道，集群中某个节点维护了某个区域的槽

- 为了防止该节点挂掉，一般对该节点进行复制，形成主从复制结构。
- 从节点会复制主节点的槽，当某个主节点故障了，因为从节点已经复制了它的槽，所以该从节点将会升级为主节点，继续服务。（与哨兵相比，在此期间，不会停止服务）

### 5.3.5. 故障检测
- 故障检测：每个节点会定时向集群中其他节点发送ping，检测对方是否在线; 
- 集群中各个节点会互相发送消息交换集群中各个节点的状态信息;
- 当某个主节点x疑似下线的数过半时，将会被标记为已下线，之后，会广播给集群中所有节点，告诉它们节点x已经下线

### 5.3.6. 故障转移/raft选主算法

会从下线的主节点的从节点中选取一个，让它成为新的主节点

新节点将会广播一条pong消息，通知其他节点自己已经变成了主节点

新主节点将接管原来已经下线的主节点，继续提供服务

# 6. Redis扩展特性

## 6.1. 发布订阅模式

- 客户端订阅服务端的频道

- 当服务端向该频道中发送消息时，频道中所有的客户端都会收到该消息，执行相应的动作 

## 6.2. 事务

### 6.2.1. SQL/Redis事务对比

SQL和Redis的事务有本质的区别

- SQL事务原理
  - innodb引擎支持的事务，采用Redo log + Undo log来实现
- Redis事务原理
  - 使用`乐观锁`，只负责监听key有没有被改动。
    - 采用watch监听某个key
    - 在执行命令时，检查该被监视的key是否已经被修改
    - 如果该key时被改动，那么事务将会被打断

与SQL事务最大的区别，Redis不支持事务回滚，即使事务在执行过程中出错，也不会回滚，将会一直执行下去，直到事务结束。 因为，开发者认为，事务执行失败，很少会在实际生产环境中出现。

## 6.3. 索引

 Redis没有实现索引，如果需要索引，需要用户自己设置并实现之 






# 7. Redis使用场景

## 7.1. String字符串对象

场景：统计网页/贴吧/文章阅读/浏览次数

```python
Incr article:readcnt:1001  # 对文章1001的读次数+1
```



## 7.2. Hash之淘宝商城购物车

## 7.3. List之微博公众号消息流

订阅了某个公众号，当该公众号发文章后，会推送给你！ 特点：消息的发送是有一个时间线的 

（微信朋友圈）

```python
LPAUSH msg:{小明微信号ID} 10018    # 发消息
LPAUSH msg:{小明微信号ID} 10011    # 发消息  
LRANGE msg:{小明微信号ID} 0 -1     # 查看最新的消息流列表
```



## 7.5.Bit位之日活量

场景：统计2020/10/03，登录用户数。现在系统有千万级活跃用户，如何实现日活统计，为了增强用户粘性，要上线一个连续打卡发放积分的功能，怎么实现连续打卡用户统计？

```python
将20201003Login作为key，offset作为每个用户，value 0/1表示都否登录，即：

Data    1  0  0  0  1  1  0 
Offset  0  1  2  3  4  5  ... ... 

Setbit 20201003Login 0 1 
Setbit 20201003Login 4 5 

bitcount 20201003Login 0 -1  # 统计日活

将20201003Login, 20201004Login,..., 20201007Login相与，之后再统计1的总个数 # 统计连续几日登录量
```



## 7.6. Set之微信抽奖小程序、微博点赞列表、微博关注模型	

无序不重复，放相同的元素，将会被去重（每个人点击多次抽奖，将会被去重，只视为一次抽奖）

场景1：微信抽奖小程序 

```python
SADD activity:10086 {用户ID}   # 用户点击抽奖按钮后，将加入set
SMEMBERS activity:10086       # 查看参与抽奖的所有用户
SRANDMEMBER activity:10086 2 SPOP activity:10086 2  # 随机抽取count名中奖者
```

场景2：微博点赞

```python
SADD like:{消息ID} {用户ID}      # 点赞
SREM like:{消息ID} {用户ID}      # 取消点赞
SISMEMBER like:{消息ID} {用户ID} # 检查用户是否点过赞
SMEMBERS like:{消息ID} {用户ID}  # 获取点赞的用户列表
SCARD like:{消息ID}             # 获取点赞用户总数
```

场景3：微博关注模型

James --\> {A,B,C} Kobe--\>{A,C,D,R} 

James、Kobe是两个集合Set 

```python
SINTER James Kobe      # 取出James和Kobe共同关注的人（交集） 
SISMEMBER James Jordan # 判断James集合中是否有Jordan 
SDIFF James Kobe       # James可能认识的人
```

场景4：Set实现电商商品类型的筛选 

```python
SADD brand:huawei P30 
SADD brand:xiaomi 6X 
SADD os:android P30 6X
SADD cpu:brand:intel P30 6X 
SADD ram:8G P30 6X
SINTER os:android cpu:brand:intel ram:8G  # -->{P30, 6X}
```



## 7.7. ZSet有序集合之微博热点排行榜

```python
ZINCRBY hotNews:20190722 1   # 点击新闻 
ZREVRANGE hotNews:20190722 0 10 WITH SCORES  # 展示当日排行前十
```

---



# 8. [Redis 6.0 的那些事](https://www.cnblogs.com/madashu/p/12832766.html)

**Redis单线程？多线程？**

之前说Redis是单线程，指的是Redis的`处理客户端请求事件`的主线程是“单线程的”，其实还是有一些后台线程在做任务。

- 主线程
  - Redis在处理客户端请求时（获取命令、解析命令、执行、返回内容）等操作都是由一个顺序串行的主线程处理的，这就是所谓的“单线程”。
- 后台线程
  - 清理脏数据、无用连接释放、大key的删除

---

**Redis6.0之前为什么之前一直不使用多线程？**

官方回应：Redis几乎不存在CPU称为瓶颈的情况，主要受限于**内存/网络**。单机QPS可以达到100万。

- 单机峰值的限制点

  > ① 网络卡
  >
  > ② 超过内存限制
  >
  > ③ Redis处理命令时，对命令要有序列化/反序列化。解决方案：
  >
  > - 使用Redis的多线程模式

场景：Redis超过内存限制，会出现什么问题

> 会根据Redis配置文件，释放内存（内存淘汰策略LRU/LFU/random）。可能释放内存的速度 < 内存增大的速度，此时就会导致Redis客户端写入错误
>
> 

---

**为什么Redis单线程模型处理速度如此快？**

- 单机QPS
  - Redis通过使用pipelining每秒可以处理100万个请求（QPS，百万级别）

- IO多路复用
  - 服务器接收客户端发来的请求命令是单线程的，它采用了IO多路复用能够同时监听多个事件的到来，当事件到来后，会将就绪事件挂到激活队列中，然后依次执行

---

**为什么Redis要一直使用单线程？**

- 多线程难以维护性
  - 增加系统复杂度：单线程的惰性删除、Rehash等操作都可以无锁实现
  - 存在线程切换，加锁解锁带来的性能消耗
- 使用多个Redis服务器组成集群，也能在一定程度上解决性能上的压力

----

**为什么Redis要引入多线程呢？**

- 随着业务场景越来越复杂，数据量越来越大，需要更大的QPS
- 使用多个Redis服务器组成集群，需要对它们进行维护，维护代价大
- 多线程能够充分的利用多核

---

**Redis6.0默认开启多线程么？如何开启和设置线程数？**

默认多线程模式是关闭的

```python
# io-threads 4
```

官方建议

- 4核机器建议设置为2或3，8核建议设置为6.（线程数一定要小于机器核数）

- 还需要注意的是，线程数并不是越大越好，官方认为超过了8个基本就没什么意义了

----

**开启多线程后，是否会存在线程并发安全问题？**

![](https://github.com/gEricy/knownledge/blob/master/A_%E6%95%B0%E6%8D%AE%E5%BA%93_SQL_Redis/%E5%8E%9F%E7%90%86%E5%9B%BE/Redis6.0%E5%A4%9A%E7%BA%BF%E7%A8%8B.png)

从上面的实现机制可以看出，Redis的多线程部分只是用来处理网络数据的读写和协议解析，（执行命令仍然是主线程顺序执行）。所以，不需要去考虑控制 key、lua、事务，LPUSH/LPOP 等等的并发及线程安全问题。

---

**Redis6.0的多线程和Memcached多线程模型进行对比**

- 相同点
  - 都采用了 master线程、worker 线程的模型
- 不同点
  - Memcached 执行主逻辑也是在 worker 线程里，模型更加简单，实现了真正的线程隔离，符合我们对线程隔离的常规理解（即：主线程采用 libevent 监听 listen、accept 的读事件，事件响应后将连接信息的数据结构封装起来，选择合适的工作线程进行后续的数据操作）
  - Redis 把处理逻辑交还给 master 线程，虽然一定程度上增加了模型复杂度，但也解决了线程并发安全等问题

# 9. Redis面试总结

​            在网上无意间，看到一个很好的贴子，里面介绍了较多面试题，也梳理了我们对问题的误区： 

- [整理了2019年40道Redis高频面试题，答案详细解析](https://www.bilibili.com/read/cv4042105/)

- [redis原理总结(很全面)](https://blog.csdn.net/wuyangyang555/article/details/82152005)
- [Redis双写一致性、并发竞争、线程模型](https://www.imooc.com/article/297496)
