# 前言

​          写在最前，本文主要以知识框架为主，根据自己对知识掌握的情况，进行知识点的梳理（有的知识点实际上上篇幅很大，但是由于自己理解，就没有详细叙述）。但是，知识体系框架是相对完善的。



# SQL关系型数据库

# 1. 索引

## 1.1. 索引是什么？

加快SQL查询速度的数据结构，引来的缺点（降低更新表的速度，保存索引占用空间）

## 1.2. 索引采用那些数据结构？

1. HASH索引：底层是哈希表，存储KV，在进行查找时，调用一次hash函数就可以找到相应的键值

2. B+Tree索引：B+树，多路平衡查找树，每次查询都是从根节点出发，查找到叶子节点就可以获得所查的值

| MySQL中的数据一般是放在磁盘中的，读取数据的时候肯定会有访问磁盘的操作，定位是磁盘的存取中花费时间比较大的一块 B+Tree是专门为磁盘IO设计的一种多路平衡查找树，它的高度远远小于其他数据结构，因此访问磁盘的数量极小，磁盘IO所花的时间少 |
| ------------------------------------------------------------ |
| B+树为什么比B树更适合？（1） B+树的内部节点不存放数据，因此其内部节点相对B树更小 （2）B+树的查询效率更加稳定：B+树的数据都存储在叶子结点中，所以任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当。 （3）由于B+树的数据都存储在叶子结点中，且叶子节点形成链表，便于区间查询 |
|                                                              |
| B树，什么时候会分裂、合并？ **自己看数据结构**               |

### 1.2.1. HASH索引和B+Tree索引对比

1. HASH索引等值查询更快，但是不支持采用key排序/范围查询/最左匹配原则/模糊查询

2. HASH函数选择不好时，会发生HASH碰撞，导致查询效率降低

3. HASH索引任何时候都避免不了回表查询，B+索引在覆盖查询时，可以避免回表查询

4. HASH索引是存放在内存中的，占用内存资源太大

### 1.2.2. 为什么底层使用B+Tree，不使用二叉树、BST、AVL、RBT

二叉树/BST会退化成链表、AVL树旋转代价太高、RBT树太高

B+Tree与BTree相比有什么优势？中间节点只存放索引、只有叶子节点存放数据；叶子节点连成链表，便于范围查询

## 1.3. 索引种类

1. 普通索引：最基本的索引，没有任何限制

2. 唯一索引：列值唯一，可以有NULL。“唯一”：加入在name上建立唯一索引，那么，整个表就不能有两个行name相同的情况

3. 组合索引，又叫联合索引

4. 全文索引：FULLTEXT，仅适用于MYISAM引擎的数据表。通过关键字的匹配来进行过滤查询

5. 聚簇索引、非聚簇索引; 主键索引、非主键索引

6. 覆盖索引

### 1.3.1. 聚簇索引、非聚簇索引

[核心区别]
聚簇索引/非聚簇索引的区别是B+树的叶子节点存放的是数据？还是指向数据的指针(一般存放的是主键值)？

[对比] 聚簇索引查询速度更快

聚簇索引：索引B+Tree的叶子节点上存放了数据行的物理地址

非聚簇索引：非聚簇索引B+Tree树的叶子节点存储的不再是行的物理位置，而是主键值；索引数据时，需要先查找到主键值，再通过二次索引查找到数据行的物理地址

【Q】聚簇索引可以有多个吗? 

​        答：不可以，聚簇索引只能有一个。 *聚簇索引*的顺序就是数据的物理存储顺序, 而对非*聚簇索引*的解释是:索引顺序与数据物理排列顺序无关。正式因为如此,所以一个表最多只能有一个*聚簇索引* 


### 1.3.2. 主键索引、非主键索引

1. 主键索引(聚簇索引)：的叶子节点上存放的是整行数据。查询时只需要查询一张表就可以得到结果

2. 非主键索引(非聚簇索引)：叶子节点上存放的是主键的值。查询时，需要扫描两个索引树(1)第一遍先通过普通索引定位到主键值id=5 (2)然后第二遍再通过聚集索引定位到具体行记录，这就是所谓的回表查询

### 1.3.3. 回表查询/覆盖索引

[问题] 非聚簇索引一定都会通过回表查找多次么？答案：不是，原因是“覆盖索引”。

覆盖索引：当sql语句的所求查询字段（select列）和查询条件字段（where子句）全都包含在一个索引中，就可以直接使用索引查询而不需要回表！

[问题] 怎么通过覆盖索引优化回表查询？

建立联合索引，使要查找的列都在索引中，避免回表查询。

### 1.3.4. Index Condition PushDown 索引下推

select \* from where name like 'zhang%' and age\>18

因为是select \* ，所以一定会触发回表查询，以下有2种查法

1. 查找zhang开头的主键，然后回表查询所有的记录，再过滤age\>18的行

2. 查找zhang开头的数据，再筛选出age\>18的记录，再回表查询所有数据

优化器会选择第2中，因为2先通过两个条件过滤会得到更少的信息，再回表查询

### 1.3.5. 组合索引(联合索引)、最左匹配原则 

[问题]什么是联合索引？为什么需要注意联合索引中的顺序？

组合索引：可以使用多个列建立一个索引，满足最左前缀匹配原则

## 1.4. 优化索引口诀 

全值匹配我最爱，最左前缀要遵守 

带头大哥不能丢，中间兄弟不能断

 索引列上少计算，范围之后全失效 

like百分写最右， 覆盖索引不写星 

不等空值还有or，索引失效要少用 

var引号不能丢，SQL高级也不难



1. 查询频率高的列、经常需要排序、分组、联合的字段建立索引

2. 创建索引的数目不宜过多，过多会占用空间，且影响表的更新速度

3. 选择唯一性索引(如学生的学号)

4. 不在索引上做运算符操作

5. 范围条件放最后：因为范围条件后的索引都会失效

6. 字符类型要加双引号

7. or替换为union：A or B，如果A建立了索引，B没有建立索引，则索引通通不走

8. like查询要当心：like %keyword索引失效，like keyword%索引有效

9. 不等于!=要慎用：索引失效

10. 考虑在where或order by 或 group by涉及的列建立索引

# 2. 存储引擎 innodb/myisam

## 2.1. 区别

|                 | InnoDB | myisam | InnoDB                                                                        | myisam               |
|-----------------|--------|--------|-------------------------------------------------------------------------------|----------------------|
| 事务            | 支持   |        | 支持事务，可靠性要求高                                                        | 不支持事务           |
| 锁级别          | 行锁   | 表锁   | 表更新较频繁                                                                  | 查询多，插入和删除少 |
| 是否支持外键    | 支持   |        |                                                                               | 做很多count(\*)运算  |
| 查询 插入和更新 | 更快   | 更快   | **两种类型最主要的差别就是Innodb 支持事务处理与外键和行级锁.而MyISAM不支持.** |                      |
| 全文索引        |        | 支持   |                                                                               |                      |

1. innodb支持事务、外键、行锁(默认)/表锁，不支持全文索引

2. innodb必须有主键，没有显示指定主键，mysql会默认创建主键_rowid；而myisam可以没有主键

3. innodb是主键索引/聚集索引，myisam是非主键索引/非聚集索引。

   也就是说：InnoDB的B+树主键索引的叶子节点就是数据文件，辅助索引的叶子节点是主键的值；而MyISAM的B+树叶子节点都是数据文件的地址指针

4. 存储文件

	innodb：frm表结构文件、ibd数据文件(包括索引/数据)

	Myisam：frm表结构文件、MYD数据文件、MYI索引文件

## 2.2. 如何选择？

innodb：支持事务、行锁、读写频繁

myisam：不支持事务、具有大量的读操作、写操作很少

## 2.3. 扩展问题/知识点

### 2.3.1. InnoDB为什么推荐使用自增ID作为主键，不用UUID？

 B+Tree底层结构：在插入的时候，(1)自增ID可以保证每次插入时B+索引是从右边扩展的(2)UUID是随机生成的，不一定key值就比之前的数大，会导致B+树和频繁合并和分裂。 另外，UUID占用16个字节，占用内存较大 


### 2.3.2. innodb无索引or索引失效时，行锁会升级为表锁

# 3. 三范式

第一范式：列不可拆分

第二范式：非主键列完全依赖于主键，而不依赖于主键的一部分

第三范式：非主键列只依赖于主键，不依赖于其他非主键

# 4. 事务 

## 4.1. 前言

多用户、多程序、多线程，保证数据一致性，引出事务

## 4.2. 特性：ACID

原子性：最小单元，整个事务的所有操作要么做，要么都不做

一致性：从一种一致性状态转换为另一种一致性状态，事务开始/结束都保证完整性

隔离性：并发执行的各个事务之间不相互干扰

持久性：事务一旦提交，结果将永久保存在数据库中

## 4.3. 事务并发问题

**賍读(读取未提交数据)**：B修改某个数据后，未提交，被A读到；之后B回滚修改数据操作，A之前读到的数据就是脏数据

**不可重复读(在一个事务中前后读取的数据不一致)**：A读取同一个数据经历的时间很长，第一次读时，该数据为Val1，之后，该数据被B修改，之后A再去读该数据，结果为Val2，这就叫做不可重复读

**幻读(前后多次读取，数据总量不一致)**：与不可重复读类似，都是在一个事务中，两次读取结果不一样。区别在于幻读是在一个事务中读取到数据的条数不一致，如：事务A在执行读取操作，需要两次统计数据的总量，前一次查询数据总量后，此时事务B执行了新增数据的操作并提交后，这个时候事务A读取的数据总量和之前统计的不一样，就像产生了幻觉一样，平白无故的多了几条数据，称为幻读

## 4.4. 事务的四种隔离级别

读未提交：所有事务都能够读取其他事务未提交的数据，会导致賍读、不可重复读、幻读

读已提交：所有事务只能读取其他事务已经提交的数据，可以解决賍读！但是会出现在一个事务中前后读取内容不一致的问题，即不可重复读、幻读

可重复读：在一个事务中，不允许Update操作，允许Add操作，因此能保证在一个事务中读取数据内容是一致的(能解决不可重复读)，但是不能保证读取到数据条目数一致(会发生幻读)

可串行化：所有的事务都顺序串行执行，不存在冲突

## 4.5. 扩展问题/知识点

### 4.5.1. innodb默认是可重复读级别（次高级，不是最高级）

## 4.6. 事务的原理

### 4.6.1. 事务日志：redo/undo（仅仅innodb）

| redo log 重做日志：保证事务持久性                                                               | undo log 回滚日志：保证事务原子性                                                                                                                          |
|-------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------|
| 在事务提交之前，先写入到redo log中，如果某时刻系统宕机，重启后，可以通过redo log恢复之前的数据  | 数据更新时，会写入undo log（该操作和数据更新执行操作相反，即如果是插入数据，则undo log是删除数据）。当事务失败或回滚时，可以通过undo log回滚到更新前的状态 |
| 数据库宕机恢复过程 先从redo log中把未落盘的脏页数据恢复回来，重新写入磁盘，保证用户数据不丢失。 |                                                                                                                                                            |
| 把未提交的事务，根据undo log执行回滚操作，恢复事务                                              |                                                                                                                                                            |

### 4.6.2. redo日志写入时机

| redolog写入真实的物理磁盘                                                     |
|-------------------------------------------------------------------------------|
| 先写入redo log buffer（redo log缓存） 之后调用fsync，刷新写入redo log物理磁盘 |
| 它的写入是可进行参数配置的。                                                  |

### 4.6.3. 二进制日志：binlog（所有存储引擎都有）

binlog与redo log类似，它也是在数据提交前，保存更新日志，但是二者还是有本质的区别

|          | redo log                       | binlog                             |
|----------|--------------------------------|------------------------------------|
| 场景     | crash-recovery宕机恢复         | point-time-recovery恢复某个时间点  |
|          | 只有innodb支持事务的存储引擎有 | 所有SQL都支持                      |
| 写入时机 | 写入时机根据配置文件           | 事务提交时写入，记录数据库更新操作 |
|          |                                | 实现主从复制（下面会介绍）         |

### 4.6.4. 分布式之两/三阶段提交

| 背景 | 在分布式环境中，会有多个节点，常出现这种场景，多副本，更新一个数据时，要使得所有节点上的数据全部更新，才认为该更新成功。但是某个节点只能知道自己节点上的事务是否执行成功，不能知道其他节点的事务是否更新。 |
| ---- | ------------------------------------------------------------ |
| 因此 | 引出了一个中间人（即协调者），它用于协调事务执行过程         |

#### 4.6.4.1. 二阶段提交



|      | 二阶段提交运作过程                                           |
| ---- | ------------------------------------------------------------ |
|      | 协调者向所有节点上的参与者发送“开始事务”的信号 **（阶段1：投票）**所有参与者执行事务，执行成功后，会应答结果给协调者（事务成功/事务失败） **（阶段2：执行）**协调者收到信号后，会根据结果，再次向参与者发送通知：全部成功，就发送“提交事务”信号；有一个失败，就发送回滚事务信号，放弃事务 ![](https://github.com/gEricy/knownledge/blob/master/2%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A4.png) |
|      |                                                              |
|      | **两阶段提交的缺点**                                         |
|      | 单点故障：只有一个协调者，它宕机后，将会造成单点故障         |
|      | 阻塞：协调者故障，所有的参与者将阻塞等待它通知，此时会一直持有事务资源 |
|      | 不一致性：协调者应答“提交事务”时，可能由于网络原因，导致某个节点没收到，该节点不会提交，造成数据不一致 |

#### 4.6.4.2. 三阶段提交

| 与两阶段提交的改进点                                         |      |
| ------------------------------------------------------------ | ---- |
| ① 加入超时，当超时机制，即参与者/协调者接收信号时，都设置超时，防止一直阻塞 |      |
| ② 三阶段：将两阶段种的第一个阶段（投票阶段），拆分成2个阶段：预投票、准备 |      |
| （阶段1预投票）：协调者向参与者询问，是不是都能开始事务（如果全部都能开始事务，则进入下一个阶段；如果有一个不能开始事务，则放弃事务）。 （阶段2）假如，协调者向参与者发送“开始执行事务”的信号 对方执行事务，并返回应答该协调者 （阶段3）协调者收到信号后，会根据结果，再次向参与者发送通知：全部成功，就发送“提交事务”信号；有一个失败，就发送回滚事务信号，放弃事务 ![]()https://github.com/gEricy/knownledge/blob/master/3%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A4.png |      |

# 5. 锁

当数据库有并发事务时，可能会产生数据不一致，锁可以保证访问次序。

## 5.1. 共享锁(读锁), 独占锁(写锁)

（1）共享锁(读锁)：可以被多个事务同时读，但是加了读锁，不允许加写锁

（2）独占锁(写锁)：加了写锁，不允许加读锁or写锁

## 5.2. 乐观锁, 悲观锁

（1）乐观锁：MySql最经常使用的乐观锁是进行[版本控制]，也就是在数据库表中增加一列，记为version。当我们将数据读出时，将版本号一并读出；当数据进行更新时，会对这个版本号进行加1；当我们提交数据时，会判断数据库表中当前的version列值和当时读出的version是否相同，若相同说明没有进行更新的操作，不然，则取消这次的操作。

（2）悲观锁：只允许一个锁进入

## 5.3. 表锁、行锁

## 5.4. 多版本并发控制MVCC \*\*

<https://www.cnblogs.com/shujiying/p/11347632.html>

# SQL优化

## 数据插入优化

| 1.插入前，禁用索引                                                                                                                                                                               |
|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| 2.修改事务的提交方式（变多次提交为一次提交） insert into test values(1,2); insert into test values(1,3); insert into test values(1,4); //合并多条为一条 insert into test values(1,2),(1,3),(1,4) |
| 3.插入后，不禁用索引                                                                                                                                                                             |

## 6.2. 单机优化

### 1. 慢查询

(1) 慢查询配置：slow_query_log、slow_query_log_file、long_query_time

(2) 慢查询日志分析工具mysqldumpslow：捕获前10条查询较慢的 mysqldumpslow -s at -t
5 xxx.log

### 2. SQL语句优化

	消除子查询，改为关联查询

### 3. 没建立索引，就建立索引

### 4. 对于已经建立的索引，可能存在索引失效

explain查看SQL语句的执行计划：possibe_key,key,key_len,using等字段，分别表示可能使用的索引，实际使用的索引，使用索引的总字节数，using
index(覆盖索引)/where(回表)/filesort(order by)/temporary(group by 临时表)

| Using字段含义 |                                                                                                                                                                                                                                                         |
|---------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| where         | 回表查询                                                                                                                                                                                                                                                |
| index         | 覆盖索引，直接通过索引就可以获取到所有要查询的数据，无需回表查询                                                                                                                                                                                        |
| filesort      | 并不是说通过磁盘文件进行排序，而只是告诉我们进行了一个排序操作而已(只有在order by 数据列的时候才可能会出现using filesort)  (1)修改逻辑，不在mysql中使用order by而是在应用中自己进行排序  (2)使用mysql索引，将待排序的内容放到索引中，直接利用索引的排序 |
| temporary     | group by 临时表                                                                                                                                                                                                                                         |

## 6.3. 集群优化

### 1. SQL/Redis主从复制

| 定义           | 将一台Redis服务器的数据，复制到其他的Redis服务器，前者后者分别称之为master/slaver，数据的复制是单向的，只能由主节点到从节点 |
| -------------- | ------------------------------------------------------------ |
| 作用           | 数据冗余：从节点保存了和主节点一样的数据 故障恢复：主节点出现问题时，从节点可以提供服务，实现故障恢复 负载均衡：在主从复制的基础上，配合读写分离，主节点提供写服务，从节点提供读服务 高可用基石：哨兵、集群实现高可用 |
| 主从 复制 原理 | ![]()https://github.com/gEricy/knownledge/blob/master/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E5%8E%9F%E7%90%86.png |
|                | 上面已经知道，数据库的DML操作，都会保存在binlog中；如何将主节点的binlog同步到各个从节点上？ 答： ①拉去日志：从数据库开启IO线程，主动拉取binlog，保存为中继日志Relay log ②日志回放：从数据库开启SQL线程，将中继日志在从服务器上重新执行（执行完成后，主从数据库数据一致）。 |

#### 重点：主从复制中延迟问题

| 定义                                        | 从服务器的两个线程执行速度不一致，可能会造成延迟问题。 因为：IO线程从主服务器读取日志速度很快（顺序读），而SQL线程重放SQL速度慢，这就会造成从服务器同步数据远远落后于主服务器，导致从服务器数据落后于主服务器（主从数据库长期处于不一致的状态），这种现象就是延迟更新。 |
| ------------------------------------------- | ------------------------------------------------------------ |
| 主从复制中延时产生的原因                    | 备库性能 \<\< 主库性能 主库经常会开多个线程去写，从库只有一个线程在工作，导致从库效率\<\<主库效率 根本原因：主库写Binlog、从库IO线程读Binlog都是顺序操作，执行速度很快；但是从库SQL线程重放操作是随机操作，很慢 主库一直在执行大事务（每个事务执行10min），而Binlog的写入必须要等待事务执行完成之后，才会传入备库，那么此时在开始执行时就已经延迟了10min |
| 解决方案： 从服务器的数据重放过程采用多线程 | ![](https://github.com/gEricy/knownledge/blob/master/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E5%BB%B6%E8%BF%9F%E6%9B%B4%E6%96%B0%E4%B9%8BMTS.png)MTS：要遵循两个规则，即对于2种情况，应该必须分发到同一个worker线程 同一个事务中的MDL，必须分发到同一个worker线程 MDL同一行的多个事务，必须分发到同一个worker线程 |

### 2. 读写分离

|      | 主库只进行更新写操作，从库进行查询读操作     |
|------|----------------------------------------------|
| 主库 | 增删改更新操作，即：更新操作，一直在主服务器 |
| 从库 | 查询操作，即：查询操作，一直在从服务器       |

### 3. 分库分表：水平/垂直

| 场景 | 随着公司业务的发展，数据库中的数据量猛增，访问性能也变慢了，优化迫在眉睫。当数据达到100W或100G后，由于查询的维度较多，即使添加从库、优化索引，很多操作仍然性能下降很大。 分库分表是为了解决数据量过大导致数据库性能降低的问题！将原来独立的数据库、表，拆分成多个数据库、表，使得单个数据库、表的数据量变小，从而达到性能优化的目的。 |
| ---- | ------------------------------------------------------------ |
|      | 垂直分表：将表按照属性列划分成多个表                         |
|      | 水平分表：数据量行数过大时，按照行分成多个表                 |
|      |                                                              |
|      | 垂直分库：按照业务将表分不到不同的数据库，每个库可以放在不同的服务器 |
|      | 水平分库                                                     |

## 6.4. 缓存redis

防止每次请求都发到数据库上，使用缓存，降低连接数据库操作、数据库处理操作次数，提高数据库性能 



# 7. 分页查询：limit

## 7.1. 超大分页怎么处理? 

答：超大的分页一般从两个方向上来解决。

① 数据库层面,这也是我们主要集中关注的(虽然收效没那么大), 类似于 select \* from
table where age \> 20 limit 1000000,10 这种查询其实也是有可以优化的余地的.
这条语句需要 load 1000000 数据然后基本上全部丢弃,只取 10
条当然比较慢。我们可以修改为 select \* from table where id in (select id from
table where age \> 20 limit 1000000,10)。这样虽然也 load
了一百万的数据,但是由于**索引覆盖**,要查询的所有字段都在索引中,所以速度会很快.

② 同时如果 ID 从0开始且连续递增的话, 我们还可以 select \* from table where id \>
1000000 limit 10,效率也是不错的

## 7.2. 结论：优化的可能性有许多种,但核心思想是减少load数据量

分页查询：如何快速定位起始位置offset、减少无用数据缓存

​        从需求的角度减少这种请求….主要是不做类似的需求(直接跳转到几百万页之后的具体某一页.只允许逐页查看或按照给定的路线走,这样可预测,可缓存)以及防止ID 泄漏且连续被人恶意攻击.

​        解决超大分页,其实主要是靠缓存,可预测性的提前查到内容,缓存至 redis 等 k-V
数据库中,直接返回即可. 在阿里巴巴《Java开发手册》中,对超大分页的解决办法是类似于上面提到的第一种.

# 8. 关联查询 join (待整理) \*\*

## 8.1. 内连接；左连接/右连接；自身连接

| **自身连接**         | select FIRST.Cno,SECOND.Cpon  \#查询每门课的先修课的先修课 form course FIRST, course SECOND \#重命名 where FIRST.Cpon=SECOND.Cno |
|----------------------|----------------------------------------------------------------------------------------------------------------------------------|
| **左连接/ 左外连接** | from A left join B on (连接条件) \#以A的行为主行,B没有的补NULL from A right join B on (连接条件) \#以B的行为主行,A没有的补NULL   |
| **内连接**           | from A inner join B on (连接条件) \#A和B的交集                                                                                   |

# 9. 其他常见问题

## 9.1. SQL常用语法&&执行顺序

|      | *select* [ALL\|DISTANCE] \<目标列表达式\> *from* \<表明或视图名\> where \<条件表达式\> group by \<列名\> having \<条件表达式\> order by \<列名\> ASC\|DESC |                              |         |
| ---- | ------------------------------------------------------------ | ---------------------------- | ------- |
| 谓词 | IN ; LIKE                                                    | IS NULL ; IS NOT NULL        | AND ;OR |
|      | Order by \<属性列\>  \#按照\<属性列\>排序                    |                              |         |
|      | Group by \<属性列\> Having 条件表达式                        | \#\<属性列\>值相等的分在一组 |         |

书写顺序：select...from...where...group by...having...order by.. 执行顺序：from...where...group by...having...select...order by...

## 9.2. 什么是存储过程？有哪些优缺点？

定义：多个SQL语句的集合，就像是函数，但是它没返回值

优点：一次连接，执行存储过程中所有的SQL语句，效率高

| 1.只在创建时编译一次，之后不编译；可以重复使用，提高开发效率                                |
|---------------------------------------------------------------------------------------------|
| 2.安全性高：可以设定某个用户是否具有某个存储过程的使用权限                                  |
| create procedure insert_student_process(name varchar(50),age int,out_id ing) //创建存储过程 |
| begin:                                                                                      |
| insert into student value(null,name,age)                                                    |
| select max(stuId) into id from student                                                      |
| end;                                                                                        |
| call insert_student_process('gjw',26,\@id); //调用存储过程                                  |
| select \@id;                                                                                |

## 9.3. 触发器：触发条件 条件满足

| 触发器：需要有触发条件，当条件满足以后做什么操作                        |
|-------------------------------------------------------------------------|
| 例如1：校内网，开心网，facebook，你发一个日志，自动通知好友，其实       |
| 就是增加日志时做的一个后触发，再向"通知表"写入条目。---\>触发器的效率高 |

## 9.4. [select \*] 和 [select 全部字段] 2种写法有什么优缺点

|                      | **select \***    | **select 全部字段** |
|----------------------|------------------|---------------------|
| 是否需要解析数据字典 | 是               | 否                  |
| 结果输出顺序         | 于建表列顺序相同 | 按指定字段顺序      |
| 表字段改名           | 无需修改         | 需要修改            |
| 是否可以建立索引优化 | 否               | 是                  |
| 可读性               | 低               | 高                  |

## 9.5. varchar、char区别

(1) 定长/变长：是否由实际存储内容决定

char是定长字段，假如申请了char(10)的空间,那么无论实际存储多少内容.该 字段都占用
10 个字符

varchar是变长的,也就是说申请的只是最大长度,占用
的空间为实际字符长度+1,最后一个字符存储使用了多长的空间.

(2) char查询效率更快

## 9.6. 海量数据存入表：将10W数据导入数据库，要求实时查看导入进度

| 将10W数据导入数据库：数据分批处理——\>多线程 |                                                                 |
|---------------------------------------------|-----------------------------------------------------------------|
|                                             | 1.将10W数据分成10份，给10个线程分别处理（每个线程处理1W个数据） |
|                                             | 2.分批次插入：将1W条数据，分块（每块100条数据）；一批一批插入   |
| 实时查看导入进度——\>触发器                  |                                                                 |
|                                             | 创建触发器，每次插入时，对全局变量加锁，更新进度                |


